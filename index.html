 <!-- FlatFy Theme - Andrea Galanti /-->
<!doctype html>
<!--[if lt IE 7]> <html class="no-js ie6 oldie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js ie7 oldie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js ie8 oldie" lang="en"> <![endif]-->
<!--[if IE 9]>    <html class="no-js ie9" lang="en"> <![endif]-->
<!--[if gt IE 9]><!--> <html> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="description" content="Fourth Multimodal Learning and Applications Workshop ">
    <meta name="author" content="">

    <title>MULA 2023</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
 
    <!-- Custom Google Web Font -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic' rel='stylesheet' type='text/css'>
	<link href='http://fonts.googleapis.com/css?family=Arvo:400,700' rel='stylesheet' type='text/css'>
	
    <!-- Custom CSS-->
    <link href="css/general.css" rel="stylesheet">
	
	 <!-- Owl-Carousel -->
    <link href="css/custom.css" rel="stylesheet">
	<link href="css/owl.carousel.css" rel="stylesheet">
    <link href="css/owl.theme.css" rel="stylesheet">
	<link href="css/style.css" rel="stylesheet">
	<link href="css/animate.css" rel="stylesheet">
	
	<!-- Magnific Popup core CSS file -->
	<link rel="stylesheet" href="css/magnific-popup.css"> 
	
	<script src="js/modernizr-2.8.3.min.js"></script>  <!-- Modernizr /-->
	<!--[if IE 9]>
		<script src="js/PIE_IE9.js"></script>
	<![endif]-->
	<!--[if lt IE 9]>
		<script src="js/PIE_IE678.js"></script>
	<![endif]-->

	<!--[if lt IE 9]>
		<script src="js/html5shiv.js"></script>
	<![endif]-->

</head>

<body id="home">

	<!-- Preloader -->
	<div id="preloader">
		<div id="status"></div>
	</div>
	
	<!-- FullScreen -->
    <div class="intro-header">
		<div class="col-xs-12 text-center abcen1">
			<h1 class="h1_home wow fadeIn" data-wow-delay="0.4s" style="text-shadow: 0 0 8px #000000;">6<sup>th</sup> Multimodal Learning and Applications Workshop</h1>
			<h3 class="h3_home wow fadeIn" data-wow-delay="0.6s" style="text-shadow: 0px 0px 4px black, 0 0 25px black"> 
				<br></br>
				<br></br>
				<p>In conjunction with <a style="color:white" href="https://cvpr2023.thecvf.com/" target="_blank"><b>CVPR 2023</b></a>. </p> <p>Vancouver, Canada </p> June 18<sup>th</sup> 2023 (Full day)</p>
				<!-- <p>Room: Seaside 7</p> -->
			</h3>
			<!--ul class="list-inline intro-social-buttons">
				<li><a href="https://twitter.com/galantiandrea" class="btn  btn-lg mybutton_cyano wow fadeIn" data-wow-delay="0.8s"><span class="network-name">Twitter</span></a>
				</li>
				<li id="download" ><a href="#downloadlink" class="btn  btn-lg mybutton_standard wow swing wow fadeIn" data-wow-delay="1.2s"><span class="network-name">Free Download</span></a>
				</li>
			</ul-->
		</div>    
        <!-- /.container -->
		<div class="col-xs-12 text-center abcen wow fadeIn">
			<div class="button_down "> 
				<a class="imgcircle wow bounceInUp" data-wow-duration="1.5s"  href="#scope"> <img class="img_scroll" src="img/icon/circle.png" alt=""> </a>
			</div>
		</div>
    </div>
	
	<!-- NavBar-->
	<nav class="navbar-default" role="navigation">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="#home">MULA 2023</a>
			</div>

			<div class="collapse navbar-collapse navbar-right navbar-ex1-collapse">
				<ul class="nav navbar-nav">
					
					<li class="menuItem"><a href="#scope">Home</a></li>
					<li class="menuItem"><a href="#submit">Submit</a></li>
					<li class="menuItem"><a href="#program">Program</a></li>
					<li class="menuItem"><a href="#invited">Invited Speakers</a></li>
					<li class="menuItem"><a href="#organizers">Organizers</a></li>	
					 <!-- <li class="menuItem"><a href="#sponsors">Sponsors</a></li>					  -->
					<li class="menuItem"><a href="#contacts">Contacts</a></li>
					<!-- <li class="menuItem"><a href="#special_issue">IJCV Special Issue</a></li> -->
					<li class="menuItem"><a href="#old_editions">Old Editions</a></li>
				</ul>
			</div>
		   
		</div>
	</nav> 
	
	<!-- Scope -->
    <div id ="scope" class="content-section-a" style="border-top: 0">

        <div class="container">
			
            <div class="row">
			
				<!--div class="col-sm-6 pull-right wow fadeInRightBig">
                    <img class="img-responsive " src="img/ipad.png" alt="">
                </div-->
				
                <div class="wow fadeInRightBig" data-animation-delay="200">   
                    <h3 class="section-heading">6<sup>th</sup> Multimodal Learning and Applications Workshop (MULA 2023)</h3>
					<!-- <div class="sub-title lead" style="text-align:center"> Best Paper Award sponsored by:</div>
                     <p class="lead"  style="text-align:center"> 
						 <a href="https://www.bosch.com/" target="_blank"><img src="img/sponsor/bosch.png" height="70"></a> 
						 &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;
						 <a href="https://www.snap.com/" target="_blank"><img src="img/sponsor/Snap-black.png" height="60"></a> 
					 </p>  -->

<!--
		    <p class="lead"  style="text-align:justify">  <b>NEWS! </b>Full recording of the event is available at <u>   <a href="https://www.youtube.com/watch?v=pHuFMcaoLio&ab_channel=MichaelYang" >https://www.youtube.com/watch?v=pHuFMcaoLio&ab_channel=MichaelYang</a>  </u>
-->
		    </p>
                    <p class="lead"  style="text-align:justify">
						The exploitation of the power of big data in the last few years led to a big step forward in many applications of Computer Vision. However, most of the tasks tackled so far are involving visual modality only, mainly due to the unbalanced number of labelled samples available among modalities (e.g., there are many huge labelled datasets for images while not as many for audio or IMU based classification), resulting in a huge gap in performance when algorithms are trained separately.<br/><br/>
						Recently, a few works have started to exploit the synchronization of multimodal streams (e.g., audio/video, RGB/depth, RGB/Lidar, visual/text, text/audio) to transfer semantic information from one modality to another reaching surprising results. Interesting applications are also proposed in a self-supervised fashion, where multiple modalities are learning correspondences without need of manual labelling, resulting in a more powerful set of features compared to those learned processing the two modalities separately. Other works have also shown that particular training paradigms allow neural networks to perform well when one of the modalities is missing due to sensor failure or unfavorable environmental conditions. These topics are gaining lots of interest in computer vision community in the recent years. <br/><br/>
						The information fusion from multiple sensors is a topic of major interest also in industry, the exponential growth of companies working on automotive, drone vision, surveillance or robotics are just a few examples. Many companies are trying to automate processes, by using a large variety of control signals from different sources. The aim of this workshop is to generate momentum around this topic of growing interest, and to encourage interdisciplinary interaction and collaboration between computer vision, multimedia, remote sensing, and robotics communities, that will serve as a forum for research groups from academia and industry. <br/><br/>
						We expect contributions involving, but not limited to, image, video, audio, depth, IR, IMU, laser, text, drawings, synthetic, etc. Position papers with feasibility studies and cross-modality issues with highly applicative flair are also encouraged. Multimodal data analysis is a very important bridge among vision, multimedia, remote sensing, and robotics, therefore we expect a positive response from these communities. <br/><br/>
						
						<b>Potential topics </b> include, but are not limited to: <br/><br/>
						<ul class="lead">
							<li>Multimodal learning</li>
							<li>Cross-modal learning</li>
							<li>Self-supervised learning for multimodal data</li>
							<li>Multimodal data generation and sensors</li>
							<li>Unsupervised learning on multimodal data</li>
							<li>Cross-modal adaptation</li>
							<li>Multimodal data fusion and data representation</li>
							<li>Multimodal transfer learning</li>
							<li>Multimodal scene understanding</li>
							<li>Vision and Language</li>
							<li>Vision and Sound</li>
							<li>Multimodal applications (e.g. drone vision, autonomous driving, industrial inspection, etc.)</li>
						</ul>
					</p>

					

					 <!--p><a class="btn btn-embossed btn-primary" href="#" role="button">View Details</a> 
					 <a class="btn btn-embossed btn-info" href="#" role="button">Visit Website</a></p-->
				</div>   
            </div>
        </div>
        <!-- /.container -->
    </div>

	<!-- Call for Papers -->
    <div id ="submit" class="content-section-b">

        <div class="container">
			
            <div class="row">
			
				<!--div class="col-sm-6 pull-right wow fadeInRightBig">
                    <img class="img-responsive " src="img/ipad.png" alt="">
                </div-->
				
                <div class="wow fadeInLeftBig" data-animation-delay="200">   
                    <h3 class="section-heading">Submission</h3>
                    
					
                    <p class="lead"  style="text-align:justify">
						Papers will be limited to 8 pages according to the  <u><a href="https://cvpr2023.thecvf.com/Conferences/2023/AuthorGuidelines" Target="blank">CVPR format</a></u> (c.f. main conference authors guidelines). 
						All papers will be reviewed by at least two reviewers with double blind policy. Papers will be selected based on relevance, significance and novelty of results, technical merit, and clarity of presentation. 
						Papers will be published in CVPR 2023 workshop proceedings. 
					</p>
					<p class="lead"  style="text-align:justify">
						All the papers should be submitted using CMT website <u><a href="https://cmt3.research.microsoft.com/MULA2023" Target="blank">https://cmt3.research.microsoft.com/MULA2023</a></u>.
					</p>

				</div>  

				<div class="wow fadeInRightBig" data-animation-delay="200">   
                    <h3 class="section-heading">Important Dates</h3>
					<!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
                    <ul class="lead">

						<!-- <del><li>Deadline for submission: March 9<sup>th</sup>, 2023 - 23:59 Pacific Standard Time</li></del>
						<b>---EXTENDED---</b> -->

						<li> Deadline for submission: March 12<sup>th</sup>, 2023 - 23:59 Pacific Standard Time </li>

						<!-- <del><li>Notification of acceptance  March 30<sup>th</sup>, 2023</li></del> -->
						<li>Notification of acceptance: March 30<sup>th</sup>, 2023</li>
						<!-- <del><li>Camera Ready submission deadline: April 6<sup>th</sup>, 2023</li></del>

						<b>---EXTENDED---</b> -->
						<li>Camera Ready submission deadline: April 6<sup>th</sup>, 2023</li>

						<li> Workshop date: June 18<sup>th</sup>, 2023 (Full day)</li>

				</ul>						
				</div>  				
            </div>
        </div>
        <!-- /.container -->
    </div>
	
	<!-- Program -->
    <div id ="program" class="content-section-a">

        <div class="container">				
                <div class="wow fadeInLeftBig" data-animation-delay="200">   
                    <h3 class="section-heading">Program</h3>
                    <p class="lead"  style="text-align:justify;font-size:15px">
						
                    	<!-- Room: Seaside 7 -->

			    <!-- <b> N.B.</b>  Time is CDT (Central Daylight Time); -->
			    
<!--
			    <p class="lead"  style="text-align:justify">  Full recording of the event is available at <u>   <a href="https://www.youtube.com/watch?v=pHuFMcaoLio&ab_channel=MichaelYang" >https://www.youtube.com/watch?v=pHuFMcaoLio&ab_channel=MichaelYang</a>  </u>
			    </p>
-->

					<p class="lead"  style="text-align:justify">	
					09:15-09:30 - Welcome from organizers and openings remarks <br>
					</p>
					<p class="lead"  style="text-align:justify">
					09:30-10:15 - Keynote 1 - <b> Nicu Sebe </b>  <br>
					</p>
					<!-- <p class="lead"  style="text-align:justify;font-size:15px;padding-left: 5em">
					  <i> Abstract: </i>  The tremendous growth of multimodal video data in recent years has increased the demand for efficient multimodal deep neural network models, particularly in domains where real-time inference is essential. While significant progress has been made on model compression and acceleration for video understanding, most existing methods rely on one-size-fits-all models, which apply the same amount of computation for all video segments across all modalities. In this talk, I will instead cover methods that adaptively change computation depending on the content of the input. In particular, in the context of audio-visual action recognition, I will describe a method that adaptively decides which modality to use for each video segment (deciding where to look at and listen to in the video), with the goal of improving both accuracy and efficiency. Finally, I will conclude my talk by describing ongoing work that integrates this technology into a system for auto-curation of sports highlights based on multimodal video understanding. <br>
					</p> -->

					<p class="lead"  style="text-align:justify">
						10:15-10:45 - Coffee break <br>
						</p>

					<p class="lead"  style="text-align:justify"> 
					10:45-11:30 - Oral Session 1 (10-min presentations + 5-min Q&A
					</p>
					<!-- <p class="lead" style="text-align:justify;font-size:15px;padding-left: 5em">
						(ID 03) - Transformer Decoders with MultiModal Regularization for Cross-Modal Food Retrieval - <i> Mustafa Shukor, Guillaume Couairon; Asya Grechka Matthieu Cord. </i> <u><a href="https://drive.google.com/file/d/1Nc79zo6ElkvI8LX359PsuBpYBn9yHG8-/view?usp=sharing">link</a> </u><br> 
						(ID 05) - Improving Multimodal Speech Recognition by Data Augmentation and Speech Representations - <i> Dan Oneață, Horia Cucu.</i> <u><a href="https://drive.google.com/file/d/1AJvULaA7qSdcQuuhKj5gBul20C4dGoZ0/view?usp=sharing">link</a> </u><br>
						(ID 19) - Coupling Vision and Proprioception for Navigation of Legged Robots - <i> Zipeng Fu, Ashish Kumar, Ananye Agarwal, Haozhi Qi, Jitendra Malik, Deepak Pathak.</i> <u><a href="https://drive.google.com/file/d/1icMaeJt6dAFkbEgvgbQ6UB9IUrV8MRh3/view?usp=sharing">link</a> </u><br>
						(ID 38) - Multi-view Multi-label Canonical Correlation Analysis for Cross-modal Matching and Retrieval - <i> Rushil Kaushal Sanghavi, Yashaswi Verma.</i> <u><a href="https://drive.google.com/file/d/1vIWNhiGuHDXsq8_jM0AOfTKD_2gfDlFS/view?usp=sharing">link</a> </u><br>				    
					</p> -->
					    
					<p class="lead"  style="text-align:justify">
					11:30-12:15 - Keynote 2 - <b> Christian Theobalt </b>  <br>
					</p>
					
					<p class="lead"  style="text-align:justify">
					12:15-13:15 - Lunch <br>
					</p>

					<p class="lead"  style="text-align:justify">
					13:15-14:00 - Keynote 3 - <b> Louis-Philippe Morency </b>  <br>
					</p>
					
					<p class="lead"  style="text-align:justify">
					14:00-14:45 - Oral Session 2  (10-min presentations + 5-min Q&A
					</p>
					<!-- <p class="lead" style="text-align:justify;font-size:15px;padding-left: 5em">
						(ID 01) - Probabilistic Compositional Embeddings for Multimodal Image Retrieval - <i>Andrei Neculai, Yanbei Chen, Zeynep Akata.</i> <u><a href="https://drive.google.com/file/d/1DMD4auDLCTHrglpA8cuqgB6RQ_SbwB7h/view?usp=sharing">link</a> </u><br>
					    (ID 02) - Coarse-to-Fine Reasoning for Visual Question Answering - <i> Binh Xuan Nguyen, Tuong Khanh Long Do, Huy Tran, Erman Tjiputra, Quang Duy Tran, Anh Nguyen. </i> <u><a href="https://drive.google.com/file/d/1X_6JjD7ykS6mPi-FawoKEO9FhlIILReq/view?usp=sharing">link</a> </u><br>
					    (ID 33) - Learning to Ask Informative Sub-Questions for Visual Question Answering - <i> Kohei Uehara, Nan Duan, Tatsuya Harada.</i> <u><a href="https://drive.google.com/file/d/14q3N4HRjXssI0ULTTOLIS3r7_keN7GbR/view?usp=sharing">link</a> </u><br>
					</p> -->

					<p class="lead"  style="text-align:justify">
						14:45-15:15 - Coffee break <br>
					</p>

					<p class="lead"  style="text-align:justify">
						15:15-16:00 - Oral Session 3  (10-min presentations + 5-min Q&A
						</p>
						<!-- <p class="lead" style="text-align:justify;font-size:15px;padding-left: 5em">
							(ID 01) - Probabilistic Compositional Embeddings for Multimodal Image Retrieval - <i>Andrei Neculai, Yanbei Chen, Zeynep Akata.</i> <u><a href="https://drive.google.com/file/d/1DMD4auDLCTHrglpA8cuqgB6RQ_SbwB7h/view?usp=sharing">link</a> </u><br>
							(ID 02) - Coarse-to-Fine Reasoning for Visual Question Answering - <i> Binh Xuan Nguyen, Tuong Khanh Long Do, Huy Tran, Erman Tjiputra, Quang Duy Tran, Anh Nguyen. </i> <u><a href="https://drive.google.com/file/d/1X_6JjD7ykS6mPi-FawoKEO9FhlIILReq/view?usp=sharing">link</a> </u><br>
							(ID 06) - Semantically Grounded Visual Embeddings for Zero-Shot Learning - <i> Shah Nawaz, Jacopo Cavazza, Alessio Del Bue.</i> <u><a href="https://drive.google.com/file/d/1-Du2iEcfJoq-wFHipNqxiYg5LuieNZHj/view?usp=sharing">link</a> </u><br>
							</p> -->

					<p class="lead"  style="text-align:justify">
					16:00-16:45 - Keynote 4 - <b> Aleksander Hołyński </b> <br> 
					</p>
					<p class="lead"  style="text-align:justify">
					16:45-16:50 - Closing Remarks <br>
					</p>
					
					<p class="lead"  style="text-align:justify">
					16:50-18:00 -  Poster Session (all papers)  <br>
					</p>

				</div>
            </div>
            <div class="container">				
                <div class="wow fadeInRightBig" data-animation-delay="200">
                </div>
            </div>
        </div>
    </div>





	<!-- Invited Speakers -->
    <div id ="invited" class="content-section-b">

        <div class="container">
			
            <div class="row">
				<div class="container">
				<div class="row wow fadeInRightBig"  data-animation-delay="200">
					<h3 class="section-heading">Invited Speakers</h3>

				
					<div class="col-sm-3 wow"  data-animation-delay="200">   
						<h4 class="section-heading"><center><a href="https://disi.unitn.it/~sebe/" target="blank">Nicu Sebe </a></center></h4>
						<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/sebe.png" alt=""></center>
					</div>
					<div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">   
						<p> Nicu Sebe is a professor in Computer Science at the University of Trento, Italy, where he is the director of the Department of Information Engineering and Computer Science.
							He is leading the research in the areas of multimedia information retrieval and human-computer interaction in computer vision applications. He was involved
							in the organization of the major conferences and workshops addressing the computer vision and human-centered  aspects of multimedia information retrieval,
							among which as a General Co-Chair of the IEEE Automatic Face and Gesture Recognition Conference, FG 2008, ACM International Conference on Image and Video
							Retrieval (CIVR) 2007 and 2010. He was a general  chair of ACM Multimedia 2013 and ACM ICMR 2017 and a program chair of ACM Multimedia 2011 and 2007,
							ECCV 2016 and ICCV 2017. He was the program chair of ICPR 2020. Currently he is the ACM SIGMM vice chair. He is a fellow of IAPR and a Senior member of ACM and IEEE. 
						</p>
				</div>
				</div>

				<div class="row wow fadeInRightBig">
					<p>  <wbr> </p>
				</div>
				<div class="row wow fadeInRightBig"  data-animation-delay="200">
					<div class="col-sm-3 wow"  data-animation-delay="200">   
						<h4 class="section-heading"><center><a href="https://people.mpi-inf.mpg.de/~theobalt/" target="blank">Christian Theobalt</a></center></h4>
						<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/theobalt.jpg" alt=""></center>
					</div>
					<div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">   
						<p> Christian Theobalt is currently a Professor of computer science and the Director of the Visual Computing and Artificial Intelligence Department, Max Planck Institute for Informatics, Saarbrücken, Germany. 
							He is also a Professor at Saarland University. He is a Co-Founder of Captury (https://www.thecaptury.com). 
							His research interests include intersection of computer graphics, computer vision, and machine learning. 
							He works on virtual humans, 3D and 4D scene reconstruction, neural rendering and neural scene representations, marker-less motion and performance capture, machine learning for graphics and vision, and new sensors for 3D acquisition. 
							He received several awards, for instance the Otto Hahn Medal of the Max-Planck Society, in 2007, the EUROGRAPHICS Young Researcher Award, in 2009, 
							the German Pattern Recognition Award, in 2012, the EUROGRAPHICS Outstanding Technical Contributions Award, in 2020, an ERC Starting Grant, in 2013, and an ERC Consolidator Grant, in 2017.
						</p>
					</div> 
				</div>		
				
				<div class="row wow fadeInRightBig">
					<p> <wbr> </p>
				</div>
				<div class="row wow fadeInRightBig"  data-animation-delay="200">
					<div class="col-sm-3 wow"  data-animation-delay="200">   
						<h4 class="section-heading"><center><a href="https://www.cs.cmu.edu/~morency/" target="blank">Louis-Philippe Morency
						</a></center></h4>
						<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/morency.jpg" alt=""></center>
					</div>
					<div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">   
						<p>  Dr. Louis-Philippe Morency is currently associate professor at the Language Technologies Institute (LTI) at Carnegie Mellon University. 
							He was formerly research assistant professor at the University of Southern California (USC) and research scientist at USC Institute for Creative Technologies where he led the Multimodal Communication and Computation Laboratory (MultiComp Lab). 
							He received his Ph.D. from MIT Computer Science and Artificial Intelligence Laboratory in 2006. 
							His main research interest is computational study of human multimodal computation, a multi-disciplinary research topic that overlays the fields of multi-modal interaction, machine learning, computer vision, social psychology and artificial intelligence. 
							He developed Watson, a real-time library for nonverbal behavior recognition and which became the de facto standard for adding perception to embodied agent interfaces. 
							He received many awards for his work on nonverbal behavior computation including four best papers awards in the last two years (at various IEEE and ACM conferences). 
						</p>
					</div> 
				</div>	
				
				<div class="row wow fadeInRightBig">
					<p> <wbr> </p>
				</div>
				<div class="row wow fadeInRightBig"  data-animation-delay="200">
					<div class="col-sm-3 wow"  data-animation-delay="200">   
						<h4 class="section-heading"><center><a href="https://holynski.org/" target="blank"> Aleksander Hołyński
						</a></center></h4>
						<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/holynski.jpeg" alt=""></center>
					</div>
					<div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">   
						<p>  Aleksander Hołyński is a research scientist at Google Research and a postdoctoral scholar at Berkeley AI Research, working with Alyosha Efros and Angjoo Kanazawa. 
							Previously, He was PhD student at the University of Washington, advised by Steve Seitz, Brian Curless, and Rick Szeliski. 
							Before the PhD, he received my B.S. at the University of Illinois at Urbana-Champaign. 
						</p>
					</div> 
				</div>	


           	 </div>
        	</div>
    	</div>
	</div>
	
	<!-- Organizers -->
    <div id="organizers" class="content-section-a"> 
		
		<div class="container">
		        <div class="row wow fadeInRightBig"  data-animation-delay="200">
				<h3 class="section-heading">Organizers</h3>
				

				<div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="200">   
					<h4 class="section-heading"><center>Michael Ying Yang</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/yang.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>University of Twente, Netherlands</i></center></h5>
				</div> 

				<div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="200">   
					<h4 class="section-heading"><center>Paolo Rota</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/rota.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>Università di Trento, Italy</i></center></h5>
				</div>
				
				<div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="">   
					<h4 class="section-heading"><center>Pietro Morerio</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/morerio.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>Istituto Italiano di Tecnologia, Italy</i></center></h5>
				</div>
				
				<!-- <div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="200">   
					<h4 class="section-heading"><center>Massimiliano Mancini</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/mancini.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>University of Tübingen, Germany </i></center></h5>
				</div> -->
				
				</div>
				
				<div class="row wow fadeInRightBig"  data-animation-delay="200">
				
				<!-- <div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="200">   
					<h4 class="section-heading"><center>Zeynep Akata</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/akata.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>University of Tübingen, Germany </i></center></h5>
				</div> -->
				
				<div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="200">   
					<h4 class="section-heading"><center>Bodo Rosenhahn</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/rosenhahn.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>Institut für Informationsverarbeitung, Leibniz-Universität Hannover, Germany</i></center></h5>
				</div>
				<div class="col-sm-3 wow fadeInRightBig"  data-animation-delay="200">   
					<h4 class="section-heading"><center>Vittorio Murino</center></h4>
					<center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="200" width="200" src="img/organizer/murino.jpg" alt=""></center>
					<h5 class="section-heading"><center><i>Istituto Italiano di Tecnologia & Università di Verona, Italy </i></center></h5>
				</div>
			</div>
        </div>
    </div>

	<!-- Program Committee -->
    <div id ="committee" class="content-section-b" style="border-top: 0">
        <div class="container">			
            <div class="row">			
				<!--div class="col-sm-6 pull-right wow fadeInRightBig">
                    <img class="img-responsive " src="img/ipad.png" alt="">
                </div-->				
                <div class="wow fadeInLeftBig" data-animation-delay="200">   
                    <h3 class="section-heading"> Acknowledgments</h3>
					<!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
					<p class="lead"  style="text-align:justify">
						We gratefully acknowledge our reviewers

						<ul class="lead">
							<!-- AJ	Piergiovanni,
							Alina	Roitberg,
							Andrea	Pilzer,
							Andrea	Zunino,
							Anelia	Angelova,
							Anil Osman	Tur,
							Arif	Mahmood,
							Carles	Ventura,
							Christoph	Reinders,
							Dario	Fontanel,
							Davide	Talon,
							Dayan	Guan,
							Enrico	Fini,
							Fabio	Cermelli,
							Giacomo	Zara,
							Gianluca	Scarpellini,
							Guanglei	Yang,
							Haidong	Zhu,
							Haoyu	Dong,
							Hari Prasanna	Das ,
							Ichraf	Lahouli,
							Jae Myung	Kim,
							Jiguo	Li,
							Karsten	Roth,
							Leonard	Salewski,
							Letitia	Parcalabescu,
							Limin	Wang,
							Mihee	Lee,
							Nicola	Dall'Asen,
							Praneet	Dutta,
							Pritish	Sahu,
							Qing	Wan,
							Rico	Jonschkowski,
							Ruggero	Ragonesi,
							Sharath	Koorathota,
							Shih-Han	Chou,
							Shyamgopal	Karthik,
							Suvarna	Kadam,
							Tal	Hakim,
							Thiago	Oliveira-Santos,
							Thomas	Hummel,
							Thomas	Theodoridis,
							Uddeshya	Upadhyay,
							Victor	Turrisi da Costa,
							Vladimir	Kniaz,
							Vladimir	Pavlovic,
							Wentong	Liao,
							Woojeong	Jin,
							Xu	Dong,
							Yanbei	Chen,
							Yoonsuck	Choe,
							Yue	Song,
							Ze	Wang. -->

						</ul> 

					</p>

					 <!--p><a class="btn btn-embossed btn-primary" href="#" role="button">View Details</a> 
					 <a class="btn btn-embossed btn-info" href="#" role="button">Visit Website</a></p-->
				</div>   
            </div>
        </div>
        <!-- /.container -->
    </div>

    <!-- Sponsor -->
     <!-- <div id ="sponsors" class="content-section-a" style="border-top: 0"> 
         <div class="container">			 
             <div class="row">			 
				<div class="col-sm-6 pull-right wow fadeInRightBig">
                    <img class="img-responsive " src="img/ipad.png" alt="">
                </div				
                 <div class="wow fadeInRightBig" data-animation-delay="200">    
                     <h3 class="section-heading"> Sponsors </h3> 
					<div class="sub-title lead">We gratefully acknowlegde our sponsors for supporting the Best Paper Award</div>
					<p> </p>
                     <p class="lead"  style="text-align:justify"> 
						 <a href="https://www.snap.com/" target="_blank"><img src="img/sponsor/Snap-black.png" width="400"></a> 
					 </p> 
					 <p> <a class="btn btn-embossed btn-info" href="https://www.snap.com/" role="button">Visit Website</a></p
					<p> &nbsp;&nbsp;</p>
					 <p class="lead"  style="text-align:justify"> 
						 <a href="https://www.bosch.com/" target="_blank"><img src="img/sponsor/bosch.png" width="400"></a> 
					 </p> 
					 <p> <a class="btn btn-embossed btn-info" href="https://www.bosch.com/" role="button">Visit Website</a></p
				 </div>    
             </div> 
         </div> 
     </div>  -->

	
	
<!-- <div id ="special_issue" class="content-section-a" style="border-top: 0">
        <div class="container">						
                <div class="wow fadeInRightBig" data-animation-delay="200">   
					<h3 class="section-heading"> IJCV Special Issue </h3>
					
					<a href="https://www.springer.com/journal/11263/updates/23159852?gclid=Cj0KCQjwhqaVBhCxARIsAHK1tiNlJcecKyxOzacWAGubPisKaHP7P6XkYYGt1xXKnuxPG-rTPP2FjV4aAmdAEALw_wcB" target="_blank"><img src="img/special_issue.png" width="1000"></a> 

					
		</div>
    </div>
     -->
<!--
     Old editions 
-->
    <div id ="old_editions" class="content-section-a" style="border-top: 0">
        <div class="container">						
                <div class="wow fadeInRightBig" data-animation-delay="200">   
					<h3 class="section-heading"> Old Editions </h3>
					
					<ul class="lead">
						<li> <b>1<sup>st</sup> edition @ ECCV 2018 - Munich, Germany </b>, <a href="https://mula2018.github.io/">https://mula2018.github.io</a> </li>
						<li> <b>2<sup>nd</sup> edition @ CVPR 2019 - Long Beach, CA </b>,  <a href="index_2019.html"> 2019 Edition</a></li>
						<li> <b>3<sup>rd</sup> edition @ CVPR 2020 - VIRTUAL </b>,  <a href="https://mul-workshop.github.io/">https://mul-workshop.github.io/</a>  </li>
						<li> <b>4<sup>th</sup> edition @ CVPR 2021 - VIRTUAL </b>,  <a href="index_2021.html"> 2021 Edition</a></li>
						<li> <b>5<sup>th</sup> edition @ CVPR 2022 - New Orleans </b>,  <a href="index_2022.html"> 2022 Edition</a></li>
						
					</ul>
		</div>
    </div>


	<div id="contacts" class="content-section-c ">
			 <!-- Contacts -->
		<div class="container">
			<div class="row">
			
				<!--div class="col-sm-6 pull-right wow fadeInRightBig">
                    <img class="img-responsive " src="img/ipad.png" alt="">
                </div-->
				
                <div class="wow fadeInLeftBig" data-animation-delay="200">   
                    <h3 class="section-heading" style="color:white">Contacts</h3>
					<!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
                    <p class="lead"  style="text-align:left;color:white">
						For additional info please contact us <u><a style="color:white" href="mailto:mula.workshop@gmail.com">here</a></u> 
					</p>
					
				</div>   
				<!-- <div class="wow fadeInLeftBig" data-animation-delay="200">   
                    <h3 class="section-heading"></h3>
                    <p class="lead"  style="text-align:right">
						©MULA2019
					</p>
					
				</div>   	 -->				
            </div>
			<div class="row">
			
						<div class="col-md-6 col-md-offset-3 text-center">
							<div >
									<div class="morph-button ">
										<button type="button"></button>
										
									</div>
							</div>
						</div>	
			</div>
		</div>
	</div>	

   
    <footer>
    
    </footer>

    <!-- JavaScript -->
    <script src="js/jquery-1.10.2.js"></script>
    <script src="js/bootstrap.js"></script>
	<script src="js/owl.carousel.js"></script>
	<script src="js/script.js"></script>
	<!-- StikyMenu -->
	<script src="js/stickUp.min.js"></script>
	<script type="text/javascript">
	  jQuery(function($) {
		$(document).ready( function() {
		  $('.navbar-default').stickUp();
		  
		});
	  });
	
	</script>
	<!-- Smoothscroll -->
	<script type="text/javascript" src="js/jquery.corner.js"></script> 
	<script src="js/wow.min.js"></script>
	<script>
	 new WOW().init();
	</script>
	<script src="js/classie.js"></script>
	<script src="js/uiMorphingButton_inflow.js"></script>
	<!-- Magnific Popup core JS file -->
	<script src="js/jquery.magnific-popup.js"></script> 
</body>

</html>
